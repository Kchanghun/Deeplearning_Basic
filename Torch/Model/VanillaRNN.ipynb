{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import train_loop,test_loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check MPS Device for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can use GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "else:\n",
    "    print('can use GPU')\n",
    "    \n",
    "mps_device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden state\n",
      " tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# t\n",
    "timesteps = 10\n",
    "# n\n",
    "input_size = 4\n",
    "# h\n",
    "hidden_size = 8\n",
    "\n",
    "# input : t, n\n",
    "random_input = np.random.random((timesteps,input_size))\n",
    "inputs = torch.tensor(random_input)\n",
    "inputs = inputs.to(dtype=torch.float32,device=mps_device)\n",
    "\n",
    "# hidden state : h,\n",
    "hidden_state_t = torch.zeros((hidden_size,),device=mps_device)\n",
    "print('hidden state\\n',hidden_state_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wx shape :  torch.Size([8, 4]) \n",
      "Wh shape :  torch.Size([8, 8]) \n",
      "b  shape :  torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "# weight for input X\n",
    "Wx = torch.rand((hidden_size,input_size),dtype=torch.float32,device=mps_device)\n",
    "\n",
    "# wiehgt for hidden state h\n",
    "Wh = torch.rand((hidden_size,hidden_size),dtype=torch.float32,device=mps_device)\n",
    "\n",
    "# bias for hidden state b\n",
    "b = torch.rand((hidden_size,),dtype=torch.float32,device=mps_device)\n",
    "\n",
    "print('Wx shape : ',Wx.shape,\\\n",
    "    '\\nWh shape : ',Wh.shape,\\\n",
    "    '\\nb  shape : ',b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Vanilla RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $h_t=\\tanh(W_xX_t+W_hh_{t-1}+b)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vanilla_RNN(X,h,Wx,Wh,b):\n",
    "    return torch.tanh(\\\n",
    "        torch.matmul(Wx,X)+torch.matmul(Wh,h)+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_hidden_states = []\n",
    "\n",
    "# iterate input's sequence for each tims step\n",
    "for input_t in inputs:\n",
    "    # compute new hidden state value\n",
    "    new_hidden = vanilla_RNN(\\\n",
    "        input_t,hidden_state_t,Wx,Wh,b)\n",
    "    \n",
    "    # save new hidden state value\n",
    "    total_hidden_states.append(list(new_hidden))\n",
    "    \n",
    "    # update hidden state\n",
    "    hidden_state_t = new_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10  x  8\n"
     ]
    }
   ],
   "source": [
    "print(len(total_hidden_states),' x ',len(total_hidden_states[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch nn.RNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 5\n",
    "hidden_size = 8\n",
    "inputs = torch.Tensor(1,10,5)\n",
    "cell = nn.RNN(input_size,hidden_size,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, _status = cell(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 8])\n",
      "torch.Size([1, 1, 8])\n",
      "tensor([True, True, True, True, True, True, True, True])\n"
     ]
    }
   ],
   "source": [
    "print(outputs.shape)\n",
    "print(_status.shape)\n",
    "print(outputs[0,9]==_status[0,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
